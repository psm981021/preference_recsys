Namespace(adam_beta1=0.9, adam_beta2=0.999, alignment_loss=True, attention_map=True, attention_probs_dropout_prob=0.5, attention_type='Cluster', augment_type='mask', batch_size=512, beta=0.2, cf_weight=0.1, checkpoint_path='output_custom/Beauty/Cluster_Attention_Hybrid/Hybrid-K(16)-R(200)_V2/UPTRec-Beauty-UPTRec_Clustered_Attention_Hybrid_mask_0.7_V2-16-512.pt', cluster_train=100, context='item_embedding', contrast_type='Hybrid', cuda_condition=True, data_dir='data/', data_file='data/Beauty.txt', data_name='Beauty', de_noise=True, device='cuda:1', do_eval=False, embedding=True, epochs=4000, gamma=0.7, gpu_id='0', hidden_act='gelu', hidden_dropout_prob=0.5, hidden_size=64, initializer_range=0.02, intent_cf_weight=0.5, item_size=12103, log_file='output_custom/Beauty/Cluster_Attention_Hybrid/Hybrid-K(16)-R(200)_V2/UPTRec-Beauty-UPTRec_Clustered_Attention_Hybrid_mask_0.7_V2-16-512.txt', log_freq=1, lr=0.001, mask_id=12102, max_seq_length=50, model_idx='UPTRec_Clustered_Attention_Hybrid_mask_0.7_V2', model_name='UPTRec', n_views=3, no_cuda=False, noise_ratio=0.0, num_attention_heads=2, num_hidden_layers=2, num_intent_clusters='16', output_dir='output_custom/Beauty/Cluster_Attention_Hybrid/Hybrid-K(16)-R(200)_V2', patience=500, rec_weight=1.5, save_pt='False', seed=1, seq_representation_instancecl_type='concatenate', seq_representation_type='concatenate', tao=0.2, temperature=0.1, train_matrix=<22363x12103 sparse matrix of type '<class 'numpy.int64'>'
	with 153776 stored elements in Compressed Sparse Row format>, training_data_ratio=1.0, user_list=['[]'], valid_attention=False, vanilla_attention=False, visualization_epoch=100, wandb=True, warm_up_epoches=400.0, weight_decay=0.0)
